{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrm2JfvyBWlSNPudPSf5pe"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#This is a project that analyzes candidate CVs and job descriptions, and returns the top 5 CVs per JD."
      ],
      "metadata": {
        "id": "eFh04SQeHaSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF data extractor\n",
        "Here we are prepping the CVs and extracting relevant data (skills, education, job role)."
      ],
      "metadata": {
        "id": "ri1VIQVP7SgD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing required libraries:"
      ],
      "metadata": {
        "id": "ZOQEu2fV7ruD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lARWq975H4-",
        "outputId": "1d42f23b-fd4a-4813-93a7-1c8d60a6de1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: pdfminer.six==20221105 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20221105)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.20.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (3.2.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (41.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber as plum\n",
        "import re, spacy, glob, os"
      ],
      "metadata": {
        "id": "p0i4gMm277gi"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSThRjWE8LcZ",
        "outputId": "b613152f-6dda-42a5-fb80-4e549fac0e54"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-19 11:13:52.365082: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parsing through the PDFs and preprocessing the text:"
      ],
      "metadata": {
        "id": "ialh48fE8Vdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extracting_text(pdf):\n",
        "    text = \"\"\n",
        "\n",
        "    for i in range(len(pdf.pages)):\n",
        "        pg = pdf.pages[i]\n",
        "        text += pg.extract_text()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "zHFBfEOx8bpT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_text(text):\n",
        "\n",
        "    text = text.replace(\"\\n\", \" \").strip()\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = text.lower()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "LsNLm8fNW_XM"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the job category of the CV:"
      ],
      "metadata": {
        "id": "9_YA7tu580oR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_category(text):\n",
        "\n",
        "     return text.split(\"\\n\")[0]"
      ],
      "metadata": {
        "id": "1dCsW9bw8_Rq"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the educational qualifications from the CV:"
      ],
      "metadata": {
        "id": "Zu2KxHNt9FhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_education(text):\n",
        "\n",
        "    keywords = [\n",
        "        \"High School\", \"Certificate\", \"Associate\", \"Diploma\", \"High School Diploma\", \"GED\", \"Undergraduate\", \"UG\", \"PG\"\n",
        "        \"B.A.\", \"BA\", \"B.S.\", \"BS\", \"B.Sc.\", \"BSc\", \"B.Engg\", \"B.Eng.\", \"BTech\", \"B.Tech\", \"Bachelor\", \"Graduate\",\n",
        "        \"M.A.\", \"M.S.\", \"M.Sc.\", \"M.Eng.\", \"MBA\", \"Master\", \"Postgraduate\",\n",
        "        \"Ph.D.\", \"Doctorate\", \"Doctor\", \"Doctor of Medicine\", \"Doctor of Science\"\n",
        "    ]\n",
        "\n",
        "    edu = []\n",
        "\n",
        "    for i in keywords:\n",
        "        pattern = r\"(?i)\\b{}\\b\".format(re.escape(i))\n",
        "        match = re.search(pattern, text)\n",
        "        if match: edu.append(match.group())\n",
        "\n",
        "    return edu"
      ],
      "metadata": {
        "id": "hIBVUoUbbPSR"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the skills from the CV:"
      ],
      "metadata": {
        "id": "lMDpY_zA9ZLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "def get_skills(text):\n",
        "    skills = []\n",
        "\n",
        "    for word in nlp(text):\n",
        "        if \"NN\" in word.tag_: skills.append(word.text)\n",
        "\n",
        "    return list(set(skills))"
      ],
      "metadata": {
        "id": "q7KFk1U6byuP"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uploading the CV dataset as a ZIP file and then extracting the CVs:"
      ],
      "metadata": {
        "id": "_REWlJvfBnBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohRrKeRnBlby",
        "outputId": "4ca878da-3e67-42ea-a4b5-03198a4fd168"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# location/path of zip file in colab runtime storage\n",
        "resume_folder = \"/content/drive/MyDrive/resumes.zip\"\n",
        "\n",
        "if zipfile.is_zipfile(resume_folder):\n",
        "    with zipfile.ZipFile(resume_folder, 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "        path = os.getcwd() + \"/\" + os.path.splitext(os.path.basename(resume_folder))[0]\n",
        "else:\n",
        "    print(\"# ERROR: Please upload a valid ZIP file with resume PDFs.\")"
      ],
      "metadata": {
        "id": "oLu8Qce2B3en"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Storing CV data embeddings:"
      ],
      "metadata": {
        "id": "iLSDqBhL-thn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skill_emb = []\n",
        "edu_emb = []\n",
        "categories = []\n",
        "\n",
        "\n",
        "pdf_directory = \"/content/resumes/\"\n",
        "#in the above variable, you have to paste the path of the extracted folder (PDF dataset folder) from Colab runtime storage\n",
        "\n",
        "all_resumes = glob.glob(os.path.join(pdf_directory, \"*.pdf\"))\n",
        "\n",
        "for pdf in all_resumes:\n",
        "    currPDF = plum.open(pdf)\n",
        "    text = extracting_text(currPDF)\n",
        "    text = preprocessing_text(text)\n",
        "\n",
        "    skill_emb.append(get_embeddings(get_skills(text)))\n",
        "    edu_emb.append(get_embeddings(get_education(text)))\n",
        "    categories.append(get_category(text))"
      ],
      "metadata": {
        "id": "TPSthxkgxzB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Job Description analyzer:\n",
        "Here we are working with 15 job descriptions from the given Hugging Face dataset."
      ],
      "metadata": {
        "id": "gKmRrxjj_u-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the dataset:"
      ],
      "metadata": {
        "id": "CwBL_Q-HAINq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "F8GS5H1lAEqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "0NGHWADPAW1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jd_dataset = load_dataset(\"jacob-hugging-face/job-descriptions\")"
      ],
      "metadata": {
        "id": "cv6HZGuGAbDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the features of 15 job roles in a dictionary:"
      ],
      "metadata": {
        "id": "ZKoBmpDzAjYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tempDict = {\n",
        "    \"company_name\" : [],\n",
        "    \"position\" : [],\n",
        "    \"req_skills\" : [],\n",
        "    \"req_edu\" : []\n",
        "}\n",
        "\n",
        "\n",
        "# jobs range\n",
        "jobs = 15\n",
        "\n",
        "\n",
        "for i in range(jobs):\n",
        "    # appending company name\n",
        "    tempDict[\"company_name\"].append(jd_dataset[\"train\"][i][\"company_name\"])\n",
        "\n",
        "    # appending offered position\n",
        "    tempDict[\"position\"].append(jd_dataset[\"train\"][i][\"position_title\"])\n",
        "\n",
        "\n",
        "    model_response = eval(jd_dataset[\"train\"][i][\"model_response\"])\n",
        "\n",
        "    # appending required skills\n",
        "    tempDict[\"req_skills\"].append(model_response[\"Required Skills\"])\n",
        "\n",
        "    # appending required education\n",
        "    tempDict[\"req_edu\"].append(model_response[\"Educational Requirements\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "uFc2OSKo0Gvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizing the skills required for a given job description:"
      ],
      "metadata": {
        "id": "Vf4kP4NoA2DE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "JD_req_skills_embeddings_list = []\n",
        "\n",
        "JD_req_edu_embeddings_list = []\n",
        "\n",
        "JD_position_list = []\n",
        "\n",
        "jobs = 10\n",
        "\n",
        "for i in range(jobs):\n",
        "\n",
        "    JD_req_skills_embeddings_list.append(get_embeddings(tempDict[\"req_skills\"][i]))\n",
        "\n",
        "    JD_req_edu_embeddings_list.append(get_embeddings(tempDict[\"req_edu\"][i]))\n",
        "\n",
        "    JD_position_list.append(tempDict[\"position\"][i])\n"
      ],
      "metadata": {
        "id": "I5AtpypoAyLT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating embeddings using DistilBERT and calculating cosine similarity:\n",
        "Now we will proceed to use DistilBERT to create the embeddings we require and then use them to calculate cosine similarities that will give us an idea of how relevant the given CV is to the job role applied for."
      ],
      "metadata": {
        "id": "tePJ99TYDC5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing the Transformers library and importing libraries:"
      ],
      "metadata": {
        "id": "0dvPzQiODlC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "wXy-h9T0DhbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "IpU4VgJLDx3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating embeddings:"
      ],
      "metadata": {
        "id": "7367kDlTD2_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "\n",
        "def get_embeddings(tokenized_array):\n",
        "    tokenized_array_input = \" \".join(tokenized_array)\n",
        "    tokenized_array_encoding = tokenizer(tokenized_array_input, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tokenized_array_embedding = model(**tokenized_array_encoding).last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "    return tokenized_array_embedding"
      ],
      "metadata": {
        "id": "ok3DyvFZD8wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine similarity calculation for Education and Skills:"
      ],
      "metadata": {
        "id": "xWm7MGEfEEJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cosine_similarity(JD_req_skills_embeddings, JD_req_edu_embeddings, CV_skills_embeddings, CV_edu_embeddings):\n",
        "\n",
        "    skills_score = cosine_similarity(JD_req_skills_embeddings, CV_skills_embeddings)\n",
        "    edu_score = cosine_similarity(JD_req_edu_embeddings, CV_edu_embeddings)\n",
        "    return (skills_score + edu_score) / 2.0"
      ],
      "metadata": {
        "id": "9kkaXM0SEDzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine similarity calculation for Category (job role) matching:"
      ],
      "metadata": {
        "id": "vQl40UAEEXqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "def get_cosine_sim_for_category(position, category):\n",
        "\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform([position, category])\n",
        "    cosine_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
        "    return cosine_sim[0][0]"
      ],
      "metadata": {
        "id": "1ukVoqvBEYii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing libraries:"
      ],
      "metadata": {
        "id": "eVJySHO6CF8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile, os"
      ],
      "metadata": {
        "id": "8buk3l4HCLh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Driver function for the project:\n",
        "This section of the code brings together all the aforementioned functions to create a functional CV-to-JD matcher."
      ],
      "metadata": {
        "id": "HgVLBnjLBJbz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main() function:"
      ],
      "metadata": {
        "id": "YkRfej4gCUqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # selected jobNum\n",
        "    jobs = 15\n",
        "\n",
        "\n",
        "\n",
        "    for i in range(jobs):\n",
        "        CV_and_score = []\n",
        "\n",
        "        for j in range(len(all_resumes)):\n",
        "\n",
        "            # calculating scores\n",
        "            skill_edu_score = get_cosine_similarity(JD_req_skills_embeddings_list[i], JD_req_edu_embeddings_list[i], skill_emb[j], edu_emb[j])\n",
        "            pos_score = get_cosine_sim_for_category(JD_position_list[i], categories[j])\n",
        "            final_score = (skill_edu_score + pos_score) / 2.0\n",
        "            CV_and_score.append((final_score[0][0], os.path.basename(all_resumes[j])))\n",
        "\n",
        "        CV_and_score.sort(key=lambda x: x[0], reverse=True)\n",
        "        top_scores = [score for score, _ in CV_and_score[:5]]\n",
        "        top_CVs = [filename for _, filename in CV_and_score[:5]]\n",
        "\n",
        "\n",
        "        print(f'\\nCompany: {tempDict[\"company_name\"][i]} ({JD_position_list[i]}): \\nTop 5 CVs: {top_CVs} \\nCorresponding Scores: {top_scores}\\n')\n",
        ""
      ],
      "metadata": {
        "id": "weciQym-CUVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scores have been left as is, in the previous cell. They can of course be modified to suit your needs."
      ],
      "metadata": {
        "id": "iNsZ1-xnHFnq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\" : main()"
      ],
      "metadata": {
        "id": "FQBTn2fiCiVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execution will begin from the above line of code."
      ],
      "metadata": {
        "id": "D_Uqg90mHTrg"
      }
    }
  ]
}