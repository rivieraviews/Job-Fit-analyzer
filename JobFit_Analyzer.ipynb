{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtM58UQIiXdkta7nc+ofpB"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#This is a project that analyzes candidate CVs and job descriptions, and returns the top 5 CVs per JD."
      ],
      "metadata": {
        "id": "eFh04SQeHaSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDF data extractor\n",
        "Here we are prepping the CVs and extracting relevant data (skills, education, job role)."
      ],
      "metadata": {
        "id": "ri1VIQVP7SgD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing required libraries:"
      ],
      "metadata": {
        "id": "ZOQEu2fV7ruD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lARWq975H4-",
        "outputId": "1d42f23b-fd4a-4813-93a7-1c8d60a6de1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.10.2)\n",
            "Requirement already satisfied: pdfminer.six==20221105 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20221105)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (9.4.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.20.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (3.2.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20221105->pdfplumber) (41.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->pdfplumber) (2.21)\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber as plum\n",
        "import re, spacy, glob, os"
      ],
      "metadata": {
        "id": "p0i4gMm277gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSThRjWE8LcZ",
        "outputId": "b613152f-6dda-42a5-fb80-4e549fac0e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-09-19 11:13:52.365082: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.2)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Parsing through the PDFs and preprocessing the text:"
      ],
      "metadata": {
        "id": "ialh48fE8Vdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extracting_text(pdf):\n",
        "    text = \"\"\n",
        "\n",
        "    for i in range(len(pdf.pages)):\n",
        "        page = pdf.pages[i]\n",
        "        text += page.extract_text()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "zHFBfEOx8bpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_text(text):\n",
        "\n",
        "    text = text.replace(\"\\n\", \" \").strip()\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = text.lower()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "LsNLm8fNW_XM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the job category of the CV:"
      ],
      "metadata": {
        "id": "9_YA7tu580oR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_category(text):\n",
        "\n",
        "     return text.split(\"\\n\")[0]"
      ],
      "metadata": {
        "id": "1dCsW9bw8_Rq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the educational qualifications from the CV:"
      ],
      "metadata": {
        "id": "Zu2KxHNt9FhE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_education(text):\n",
        "\n",
        "    keywords = [\n",
        "        \"High School\", \"Certificate\", \"Associate\", \"Diploma\", \"High School Diploma\", \"GED\", \"Undergraduate\", \"UG\", \"PG\"\n",
        "        \"B.A.\", \"BA\", \"B.S.\", \"BS\", \"B.Sc.\", \"BSc\", \"B.Engg\", \"B.Eng.\", \"BTech\", \"B.Tech\", \"Bachelor\", \"Graduate\",\n",
        "        \"M.A.\", \"MA\", \"M.S.\", \"MS\", \"M.Sc.\", \"MSc\", \"M.Eng.\", \"MTech\", \"M.Tech\", \"MBA\", \"Master\", \"Postgraduate\",\n",
        "        \"Ph.D.\", \"PhD\", \"Doctorate\", \"Doctor\", \"Doctor of Medicine\", \"Doctor of Science\"\n",
        "    ]\n",
        "\n",
        "    edu = []\n",
        "\n",
        "    for i in keywords:\n",
        "        pattern = r\"(?i)\\b{}\\b\".format(re.escape(i))\n",
        "        match = re.search(pattern, text)\n",
        "        if match: edu.append(match.group())\n",
        "\n",
        "    return edu"
      ],
      "metadata": {
        "id": "hIBVUoUbbPSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting the skills from the CV:"
      ],
      "metadata": {
        "id": "lMDpY_zA9ZLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "\n",
        "def get_skills(text):\n",
        "    skills = []\n",
        "\n",
        "    for i in nlp(text):\n",
        "        if \"NN\" in i.tag_: skills.append(i.text)\n",
        "\n",
        "    return list(set(skills))"
      ],
      "metadata": {
        "id": "q7KFk1U6byuP"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Uploading the CV dataset as a ZIP file and then extracting the CVs:"
      ],
      "metadata": {
        "id": "_REWlJvfBnBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohRrKeRnBlby",
        "outputId": "4ca878da-3e67-42ea-a4b5-03198a4fd168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# location/path of zip file in colab runtime storage\n",
        "resume_folder = \"/content/drive/MyDrive/resumes.zip\"\n",
        "\n",
        "if zipfile.is_zipfile(resume_folder):\n",
        "    with zipfile.ZipFile(resume_folder, 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "        path = os.getcwd() + \"/\" + os.path.splitext(os.path.basename(resume_folder))[0]\n",
        "else:\n",
        "    print(\"# ERROR: Please upload a valid ZIP file with resume PDFs.\")"
      ],
      "metadata": {
        "id": "oLu8Qce2B3en"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Storing CV data embeddings:"
      ],
      "metadata": {
        "id": "iLSDqBhL-thn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GwapK5YYUoR",
        "outputId": "61580a36-b3eb-4ae0-ad08-7ee91af1f81e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "\n",
        "skillembeds = []\n",
        "edembeds = []\n",
        "jobroles = []\n",
        "\n",
        "pdf_directory = \"/content/resumes/\"\n",
        "# In the above variable, you have to paste the path of the extracted folder (PDF dataset folder) from Colab runtime storage\n",
        "\n",
        "all_resumes = glob.glob(os.path.join(pdf_directory, \"*.pdf\"))\n",
        "\n",
        "# Use tqdm to add a progress bar\n",
        "for pdf in tqdm.tqdm(all_resumes):  # Use tqdm.tqdm instead of enumerate\n",
        "    currPDF = plum.open(pdf)\n",
        "    text = extracting_text(currPDF)\n",
        "    text = preprocessing_text(text)\n",
        "\n",
        "    skillembeds.append(get_embeddings(get_skills(text)))\n",
        "    edembeds.append(get_embeddings(get_education(text)))\n",
        "    jobroles.append(get_category(text))\n"
      ],
      "metadata": {
        "id": "TPSthxkgxzB6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a829770-9b65-4df2-b90a-3115ffec64fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2484/2484 [1:11:23<00:00,  1.72s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Job Description analyzer:\n",
        "Here we are working with 15 job descriptions from the given Hugging Face dataset."
      ],
      "metadata": {
        "id": "gKmRrxjj_u-U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the dataset:"
      ],
      "metadata": {
        "id": "CwBL_Q-HAINq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8GS5H1lAEqD",
        "outputId": "fccc477c-f5e4-44f4-d992-c959eae47171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "0NGHWADPAW1T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jd_dataset = load_dataset(\"jacob-hugging-face/job-descriptions\")"
      ],
      "metadata": {
        "id": "cv6HZGuGAbDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving the features of 15 job roles in a dictionary:"
      ],
      "metadata": {
        "id": "ZKoBmpDzAjYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jobfeatures = {\n",
        "    \"company_name\" : [],\n",
        "    \"position\" : [],\n",
        "    \"req_skills\" : [],\n",
        "    \"req_edu\" : []\n",
        "}\n",
        "\n",
        "\n",
        "# jobs range\n",
        "jobs = 12\n",
        "\n",
        "\n",
        "for i in tqdm.tqdm(range(jobs)):\n",
        "    # appending company name\n",
        "    jobfeatures[\"company_name\"].append(jd_dataset[\"train\"][i][\"company_name\"])\n",
        "\n",
        "    # appending offered position\n",
        "    jobfeatures[\"position\"].append(jd_dataset[\"train\"][i][\"position_title\"])\n",
        "\n",
        "\n",
        "    model_response = eval(jd_dataset[\"train\"][i][\"model_response\"])\n",
        "\n",
        "    # appending required skills\n",
        "    jobfeatures[\"req_skills\"].append(model_response[\"Required Skills\"])\n",
        "\n",
        "    # appending required education\n",
        "    jobfeatures[\"req_edu\"].append(model_response[\"Educational Requirements\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "uFc2OSKo0Gvf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c626c5-0225-4302-fbab-15e359f31058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:00<00:00, 1105.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizing the skills required for a given job description:"
      ],
      "metadata": {
        "id": "Vf4kP4NoA2DE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jd_skillembedsList = []\n",
        "jd_EdEmbedsList = []\n",
        "jd_positions = []\n",
        "\n",
        "for i in tqdm.tqdm(range(jobs)):\n",
        "\n",
        "    jd_skillembedsList.append(get_embeddings(jobfeatures[\"req_skills\"][i]))\n",
        "\n",
        "    jd_EdEmbedsList.append(get_embeddings(jobfeatures[\"req_edu\"][i]))\n",
        "\n",
        "    jd_positions.append(jobfeatures[\"position\"][i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5AtpypoAyLT",
        "outputId": "413ea111-262b-4653-c0bf-3b4102a26473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [00:09<00:00,  1.26it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating embeddings using DistilBERT and calculating cosine similarity:\n",
        "Now we will proceed to use DistilBERT to create the embeddings we require and then use them to calculate cosine similarities that will give us an idea of how relevant the given CV is to the job role applied for."
      ],
      "metadata": {
        "id": "tePJ99TYDC5i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing the Transformers library and importing libraries:"
      ],
      "metadata": {
        "id": "0dvPzQiODlC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXy-h9T0DhbZ",
        "outputId": "239664c5-f349-4764-a367-b1efcc77b6a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "IpU4VgJLDx3-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating embeddings:"
      ],
      "metadata": {
        "id": "7367kDlTD2_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "\n",
        "def get_embeddings(tokenArray):\n",
        "    tokenArrayInput = \" \".join(tokenArray)\n",
        "    tokenArrayEncode = tokenizer(tokenArrayInput, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        tokenArrayEmbeds = model(**tokenArrayEncode).last_hidden_state.mean(dim=1).numpy()\n",
        "\n",
        "    return tokenArrayEmbeds"
      ],
      "metadata": {
        "id": "ok3DyvFZD8wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine similarity calculation for Education and Skills:"
      ],
      "metadata": {
        "id": "xWm7MGEfEEJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cos_similarity_scores(jd_skillembedsList, jd_EdEmbedsList, cvSkillEmbeds, cvEdEmbeds):\n",
        "\n",
        "    skillScore = cosine_similarity(jd_skillembedsList, cvSkillEmbeds)\n",
        "    edScore = cosine_similarity(jd_EdEmbedsList, cvEdEmbeds)\n",
        "    return (skillScore + edScore) / 2.0"
      ],
      "metadata": {
        "id": "9kkaXM0SEDzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine similarity calculation for Category (job role) matching:"
      ],
      "metadata": {
        "id": "vQl40UAEEXqR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "def category_similarity_score(position, category):\n",
        "\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform([position, category])\n",
        "    cosineScore = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n",
        "    return cosineScore[0][0]"
      ],
      "metadata": {
        "id": "1ukVoqvBEYii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing libraries:"
      ],
      "metadata": {
        "id": "eVJySHO6CF8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile, os"
      ],
      "metadata": {
        "id": "8buk3l4HCLh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Driver function for the project:\n",
        "This section of the code brings together all the aforementioned functions to create a functional CV-to-JD matcher."
      ],
      "metadata": {
        "id": "HgVLBnjLBJbz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### main() function:"
      ],
      "metadata": {
        "id": "YkRfej4gCUqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "\n",
        "    for i in tqdm.tqdm(range(jobs)):\n",
        "        CV_and_score = []\n",
        "\n",
        "        for j in range(len(all_resumes)):\n",
        "\n",
        "            # calculating scores\n",
        "            skill_edu_score = cos_similarity_scores(jd_skillembedsList[i], jd_EdEmbedsList[i], skillembeds[j], edembeds[j])\n",
        "            pos_score = category_similarity_score(jd_positions[i], jobroles[j])\n",
        "            final_score = (skill_edu_score + pos_score) / 2.0\n",
        "            CV_and_score.append((final_score[0][0], os.path.basename(all_resumes[j])))\n",
        "\n",
        "        CV_and_score.sort(key=lambda x: x[0], reverse=True)\n",
        "        top_scores = [score for score, _ in CV_and_score[:5]]\n",
        "        top_CVs = [filename for _, filename in CV_and_score[:5]]\n",
        "\n",
        "\n",
        "        print(f'\\nCompany: {jobfeatures[\"company_name\"][i]} ({jd_positions[i]}): \\nTop 5 CVs: {top_CVs} \\nCorresponding Scores: {top_scores}\\n')\n"
      ],
      "metadata": {
        "id": "weciQym-CUVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scores have been left as is, in the previous cell. They can of course be modified to suit your needs."
      ],
      "metadata": {
        "id": "iNsZ1-xnHFnq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calling main() function"
      ],
      "metadata": {
        "id": "7xbnZQ1hrOd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\" : main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQBTn2fiCiVU",
        "outputId": "55720ae5-9624-4e61-da44-14e2cc1904db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 1/12 [00:12<02:21, 12.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Company: Google (Sales Specialist): \n",
            "Top 5 CVs: ['10289113.pdf', '34131484.pdf', '24767027.pdf', '12082377.pdf', '30608780.pdf'] \n",
            "Corresponding Scores: [0.33589116, 0.33202514, 0.32912737, 0.32709986, 0.32338458]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 17%|█▋        | 2/12 [00:25<02:08, 12.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Company: Apple (Apple Solutions Consultant): \n",
            "Top 5 CVs: ['15535920.pdf', '38457612.pdf', '15119529.pdf', '64017585.pdf', '26291616.pdf'] \n",
            "Corresponding Scores: [0.3421532, 0.33897674, 0.33826032, 0.33602178, 0.3348015]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 25%|██▌       | 3/12 [00:39<02:00, 13.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Company: Netflix (Licensing Coordinator - Consumer Products): \n",
            "Top 5 CVs: ['10480456.pdf', '51018476.pdf', '50328713.pdf', '15858254.pdf', '87867370.pdf'] \n",
            "Corresponding Scores: [0.33528876, 0.3334325, 0.33145708, 0.33035538, 0.33005083]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 33%|███▎      | 4/12 [00:53<01:49, 13.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Company: Robert Half (Web Designer): \n",
            "Top 5 CVs: ['13807808.pdf', '93828034.pdf', '29147100.pdf', '62312955.pdf', '32532982.pdf'] \n",
            "Corresponding Scores: [0.35622367, 0.3560481, 0.35599315, 0.3549928, 0.35468218]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 42%|████▏     | 5/12 [01:08<01:37, 13.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Company: TrackFive (Web Developer): \n",
            "Top 5 CVs: ['43311839.pdf', '22351830.pdf', '93828034.pdf', '35990852.pdf', '17823436.pdf'] \n",
            "Corresponding Scores: [0.36084867, 0.34385094, 0.341695, 0.34035295, 0.34009996]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 6/12 [01:22<01:24, 14.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Company: DesignUps (Frontend Web Developer): \n",
            "Top 5 CVs: ['43311839.pdf', '51018476.pdf', '35990852.pdf', '12415691.pdf', '44115326.pdf'] \n",
            "Corresponding Scores: [0.34570694, 0.3386988, 0.338319, 0.3368676, 0.33641312]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 58%|█████▊    | 7/12 [01:36<01:10, 14.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Company: Equisolve, Inc. (Remote Website Designer): \n",
            "Top 5 CVs: ['51018476.pdf', '32532982.pdf', '13807808.pdf', '14413257.pdf', '13014900.pdf'] \n",
            "Corresponding Scores: [0.34892586, 0.3485852, 0.3465865, 0.345316, 0.34213883]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 67%|██████▋   | 8/12 [01:49<00:54, 13.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Company: Zander Insurance Agency (Web Designer): \n",
            "Top 5 CVs: ['93828034.pdf', '32532982.pdf', '14413257.pdf', '13807808.pdf', '13014900.pdf'] \n",
            "Corresponding Scores: [0.35623568, 0.3552892, 0.3537671, 0.35243168, 0.35243148]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 75%|███████▌  | 9/12 [02:02<00:40, 13.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Company: Tuff (Web Designer): \n",
            "Top 5 CVs: ['93828034.pdf', '32532982.pdf', '14413257.pdf', '13807808.pdf', '13014900.pdf'] \n",
            "Corresponding Scores: [0.35794306, 0.35656658, 0.35544786, 0.35465357, 0.35365656]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 83%|████████▎ | 10/12 [02:16<00:27, 13.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Company: General Dynamics Information Technology (SR. Web Designer): \n",
            "Top 5 CVs: ['29524570.pdf', '51018476.pdf', '78149576.pdf', '93828034.pdf', '69243180.pdf'] \n",
            "Corresponding Scores: [0.29126108, 0.2848642, 0.28183237, 0.27538842, 0.2751118]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 92%|█████████▏| 11/12 [02:31<00:13, 13.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Company: Sony Music Entertainment (Web Developer): \n",
            "Top 5 CVs: ['43311839.pdf', '22351830.pdf', '93828034.pdf', '17823436.pdf', '35990852.pdf'] \n",
            "Corresponding Scores: [0.35823363, 0.3417488, 0.3402963, 0.3386415, 0.33855093]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 12/12 [02:45<00:00, 13.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Company: Snapshot Interactive (Web Developer): \n",
            "Top 5 CVs: ['43311839.pdf', '93828034.pdf', '29524570.pdf', '16186411.pdf', '36758947.pdf'] \n",
            "Corresponding Scores: [0.28815103, 0.2793807, 0.27754253, 0.27396056, 0.27330464]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execution will begin from the above line of code."
      ],
      "metadata": {
        "id": "D_Uqg90mHTrg"
      }
    }
  ]
}